{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1khhgRBB5lmvi3DUgX6/e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjw8793/DS2023-HateCrimeAnalysis/blob/main/Hypothesis_test(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukE0s0a-8vqw",
        "outputId": "1018fa17-e766-4fde-d42f-119d03022b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/SSU2023_1/DataScience/dataset\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd \"/content/gdrive/MyDrive/SSU2023_1/DataScience/dataset\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random"
      ],
      "metadata": {
        "id": "F111Km-E_dvC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing - 데이터 합치기\n",
        "### 인구수 기반으로 정규화한 데이터 & 주별 소득 & 주별 인종 비율"
      ],
      "metadata": {
        "id": "X4uaNCuBBrhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_pop_2017 = pd.read_csv('normalized_dataset_2017.csv')\n",
        "norm_pop_2018 = pd.read_csv('normalized_dataset_2018.csv')\n",
        "norm_pop_2019 = pd.read_csv('normalized_dataset_2019.csv')\n",
        "norm_pop_2020 = pd.read_csv('normalized_dataset_2020.csv')\n",
        "norm_pop_2021 = pd.read_csv('normalized_dataset_2021.csv')\n",
        "\n",
        "income_2017 = pd.read_csv('income2017.csv')\n",
        "income_2018 = pd.read_csv('income2018.csv')\n",
        "income_2019 = pd.read_csv('income2019.csv')\n",
        "income_2020 = pd.read_csv('income2020.csv')\n",
        "income_2021 = pd.read_csv('income2021.csv')\n",
        "\n",
        "df1_2017 = pd.merge(norm_pop_2017, income_2017, on='state_name')\n",
        "df1_2018 = pd.merge(norm_pop_2018, income_2018, on='state_name')\n",
        "df1_2019 = pd.merge(norm_pop_2019, income_2019, on='state_name')\n",
        "df1_2020 = pd.merge(norm_pop_2020, income_2020, on='state_name')\n",
        "df1_2021 = pd.merge(norm_pop_2021, income_2021, on='state_name')\n",
        "\n",
        "df1_2017 = df1_2017.drop(['number_of_victims_normalized','number_of_offenders_normalized'], axis=1)\n",
        "df1_2018 = df1_2018.drop(['number_of_victims_normalized','number_of_offenders_normalized'], axis=1)\n",
        "df1_2019 = df1_2019.drop(['number_of_victims_normalized','number_of_offenders_normalized'], axis=1)\n",
        "df1_2020 = df1_2020.drop(['number_of_victims_normalized','number_of_offenders_normalized'], axis=1)\n",
        "df1_2021 = df1_2021.drop(['number_of_victims_normalized','number_of_offenders_normalized'], axis=1)\n",
        "\n",
        "norm_race_2017 = pd.read_csv('norm_2017_race.csv')\n",
        "norm_race_2018 = pd.read_csv('norm_2018_race.csv')\n",
        "norm_race_2019 = pd.read_csv('norm_2019_race.csv')\n",
        "norm_race_2020 = pd.read_csv('norm_2020_race.csv')\n",
        "norm_race_2021 = pd.read_csv('norm_2021_race.csv')\n",
        "\n",
        "# 각 데이터프레임에서 컬럼 이름 변경\n",
        "norm_race_2017 = norm_race_2017.rename(columns={'State': 'state_name'})\n",
        "norm_race_2018 = norm_race_2018.rename(columns={'State': 'state_name'})\n",
        "norm_race_2019 = norm_race_2019.rename(columns={'State': 'state_name'})\n",
        "norm_race_2020 = norm_race_2020.rename(columns={'State': 'state_name'})\n",
        "norm_race_2021 = norm_race_2021.rename(columns={'State': 'state_name'})\n",
        "\n",
        "\n",
        "df2_2017 = pd.merge(norm_race_2017, income_2017, on='state_name')\n",
        "df2_2018 = pd.merge(norm_race_2018, income_2018, on='state_name')\n",
        "df2_2019 = pd.merge(norm_race_2019, income_2019, on='state_name')\n",
        "df2_2020 = pd.merge(norm_race_2020, income_2020, on='state_name')\n",
        "df2_2021 = pd.merge(norm_race_2021, income_2021, on='state_name')\n",
        "\n",
        "data_2017 = pd.merge(df1_2017 , norm_race_2017, on='state_name')\n",
        "data_2018 = pd.merge(df1_2018, norm_race_2018, on='state_name')\n",
        "data_2019 = pd.merge(df1_2019, norm_race_2019, on='state_name')\n",
        "data_2020 = pd.merge(df1_2020, norm_race_2020, on='state_name')\n",
        "data_2021 = pd.merge(df1_2021, norm_race_2021, on='state_name')\n"
      ],
      "metadata": {
        "id": "G67q2FxuBtrT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 상관분석 _ 피어슨 상관계수 사용\n",
        "#### 주별 소득수준과 범죄횟수 간의 상관관계 파악"
      ],
      "metadata": {
        "id": "erSNK7q6Bxh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "피어슨 상관 계수는 연속형 변수 간의 상관 관계를 평가하는 데 적합하며, 스피어만 상관 계수는 순위 형태의 변수 또는 비선형 관계를 갖는 변수 간의 상관 관계를 평가하는 데 적합"
      ],
      "metadata": {
        "id": "Zz9RTx70CBJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 연도별 데이터를 담을 빈 리스트 생성\n",
        "correlation_results = []\n",
        "\n",
        "# 연도별로 데이터 분할 및 피어슨 상관 계수 계산\n",
        "for year in range(2017, 2022):\n",
        "    # 해당 연도의 데이터프레임 선택\n",
        "    data = globals()[f\"data_{year}\"]\n",
        "    \n",
        "    # column선택 : state_name, hate_crime_case_normalized, median_income\n",
        "    selected_data = data[['state_name', 'hate_crime_case_normalized', 'median_income']]\n",
        "    \n",
        "    # 피어슨 상관 계수 계산\n",
        "    pearson_corr = selected_data['hate_crime_case_normalized'].corr(selected_data['median_income'], method='pearson')\n",
        "    \n",
        "    # 결과를 딕셔너리로 저장\n",
        "    correlation_results.append({'Year': year, 'Pearson Correlation Coefficient': pearson_corr})\n",
        "\n",
        "    # 산점도 출력\n",
        "    x = data['median_income']\n",
        "    y = data['hate_crime_case_normalized']\n",
        "\n",
        "    # 산점도 그리기\n",
        "    # plt.scatter(x, y)\n",
        "    # plt.xlabel('Median Income')\n",
        "    # plt.ylabel('Hate Crime Case Normalized')\n",
        "    # plt.title('Scatter Plot of Median Income vs. Hate Crime Case Normalized')\n",
        "    # plt.show()\n",
        "\n",
        "# 결과 출력\n",
        "for result in correlation_results:\n",
        "    print(f\"Year: {result['Year']}, Pearson Correlation Coefficient: {result['Pearson Correlation Coefficient']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1R2SxQhB6uj",
        "outputId": "11f75366-aebf-4cfa-a4bb-3d32f9442645"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Year: 2017, Pearson Correlation Coefficient: 0.5026505362463362\n",
            "Year: 2018, Pearson Correlation Coefficient: 0.5460568674434366\n",
            "Year: 2019, Pearson Correlation Coefficient: 0.6174406329516006\n",
            "Year: 2020, Pearson Correlation Coefficient: 0.5026584234922596\n",
            "Year: 2021, Pearson Correlation Coefficient: 0.3288552548021082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# 연도별 데이터 파일명 리스트\n",
        "datasets = [data_2017, data_2018, data_2019, data_2020, data_2021]\n",
        "\n",
        "# 다중 회귀 분석을 위한 빈 DataFrame 생성\n",
        "results_df = pd.DataFrame(columns=['Year', 'R-squared', 'Median Income Coef', 'Black Coef', 'Hispanic Coef', 'Asian Coef', 'Multiple Coef', 'Others Coef'])\n",
        "\n",
        "# 연도별로 다중 회귀 분석 수행\n",
        "for year, dataset in zip(range(2017, 2022), datasets):\n",
        "    # 데이터 로드\n",
        "    data = dataset\n",
        "\n",
        "    # 결측값 및 무한값 처리\n",
        "    data = data.replace([np.inf, -np.inf], np.nan)\n",
        "    data = data.dropna()  # 결측값이 있는 행 제거\n",
        "\n",
        "    # 독립 변수(X)와 종속 변수(Y) 설정\n",
        "    X = data[['median_income', 'Black', 'Hispanic', 'Asian', 'Multiple', 'Others']]  # 독립 변수 열 선택\n",
        "    y = data['hate_crime_case_normalized']  # 종속 변수 선택\n",
        "\n",
        "    # 상수(intercept) 추가\n",
        "    X = sm.add_constant(X)\n",
        "\n",
        "    # 다중 회귀 모델 피팅\n",
        "    model = sm.OLS(y, X)\n",
        "    results = model.fit()\n",
        "\n",
        "    # 회귀 분석 결과 저장\n",
        "    results_df.loc[year] = [year, results.rsquared, results.params['median_income'], results.params['Black'], results.params['Hispanic'], results.params['Asian'], results.params['Multiple'], results.params['Others']]\n",
        "\n",
        "# 결과 출력\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tQeqAUrB6mY",
        "outputId": "f400661d-5682-440a-d82a-d6e23feedcc3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Year  R-squared  Median Income Coef  Black Coef  Hispanic Coef  \\\n",
            "2017  2017.0   0.744085            0.000002    1.228871      32.475790   \n",
            "2018  2018.0   0.145714           -0.000204   -0.291139      -9.081578   \n",
            "2019  2019.0   0.473207            0.000468    1.433336       6.330653   \n",
            "2020  2020.0   0.811278            0.000475    1.044078       8.403950   \n",
            "2021  2021.0   0.548291            0.000590    0.725851      50.562129   \n",
            "\n",
            "      Asian Coef  Multiple Coef  Others Coef  \n",
            "2017  121.654301       4.241668          0.0  \n",
            "2018    3.259572      11.062084          0.0  \n",
            "2019    4.016121      10.874429          0.0  \n",
            "2020   37.930174      14.209763          0.0  \n",
            "2021   -5.200683       7.171501          0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 분산분석(ANOVA)\n",
        "### 종속변수가 정규분포를 따르지 않기 때문에 분산분석은 활용X\n",
        "### -> 비모수적인 분석 방법 사용 : e.g., 크루스칼-월리스 검정,Mann-Whitney U (검정그룹간의 중앙값이 서로 다른지를 비교하는 검정), 회귀 분석, 스피어만 상관 계수 등"
      ],
      "metadata": {
        "id": "Vtz7G2LUD_9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import scipy.stats as stats\n",
        "\n",
        "# datasets = [data_2017, data_2018, data_2019, data_2020, data_2021]\n",
        "\n",
        "# for i, data in enumerate(datasets):\n",
        "#     print(f\"Year: {2017 + i}\")\n",
        "# # 크루스칼-월리스 검정 수행\n",
        "#     formula = 'hate_crime_case_normalized ~ state_name'\n",
        "#     result = stats.kruskal(*[data[data['state_name'] == state]['hate_crime_case_normalized'] for state in data['state_name'].unique()])\n",
        "\n",
        "#     print(f\"p-value: {result.pvalue}\")\n",
        "\n",
        "# print()\n"
      ],
      "metadata": {
        "id": "qPr5O4pwD_Zg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rIna7albZvjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 가설설정\n",
        "### \"소득 수준과 범죄횟수는 반비례 관계일 것이다.\"\n",
        "#### 귀무가설(null_hypothesis) : 소득수준과 범죄횟수 간에 관계가 없다.\n",
        "#### 대립가설(alternative hypothesis) : 소득수준이 높아질수록 범죄횟수는 낮다."
      ],
      "metadata": {
        "id": "GR7X0Cst958o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 유의수준 설정\n",
        "#### 0.05로 설정"
      ],
      "metadata": {
        "id": "uNx2OmvU-DUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 검정통계량 산출"
      ],
      "metadata": {
        "id": "owwOV5H9-5Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# List of datasets\n",
        "datasets = [data_2017, data_2018, data_2019, data_2020, data_2021]\n",
        "\n",
        "# Perform regression analysis for each dataset\n",
        "for i, data in enumerate(datasets):\n",
        "    print(f\"Dataset: data_{2017 + i}\")\n",
        "    \n",
        "    # Select relevant columns\n",
        "    selected_data = data[['state_name', 'hate_crime_case_normalized', 'median_income']]\n",
        "    \n",
        "    # Create regression model\n",
        "    X = selected_data['median_income']\n",
        "    X = sm.add_constant(X)\n",
        "    y = selected_data['hate_crime_case_normalized']\n",
        "    model = sm.OLS(y, X)\n",
        "    \n",
        "    # Fit the regression model\n",
        "    results = model.fit()\n",
        "    \n",
        "    # Print p-value\n",
        "    print(\"P-value:\", results.pvalues['median_income'])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3c0fKrA_A-6",
        "outputId": "9f5a13bb-7620-46b8-b298-55b3c5332f4c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: data_2017\n",
            "P-value: 0.00017068995397843416\n",
            "\n",
            "Dataset: data_2018\n",
            "P-value: 4.940820673264162e-05\n",
            "\n",
            "Dataset: data_2019\n",
            "P-value: 1.3917103990576532e-06\n",
            "\n",
            "Dataset: data_2020\n",
            "P-value: 0.00017064324446323457\n",
            "\n",
            "Dataset: data_2021\n",
            "P-value: 0.0184617865690403\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######모든 데이터셋의 p-value 값 < 유의수준 0.05\n",
        "###### ==> 귀무가설 기각. 대립가설 채택 => 즉, 소득수준과 혐오범죄수 간에는 유의미한 음의 상관 관계가 있음을 의미"
      ],
      "metadata": {
        "id": "vJB47X_UAXO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 주성분 분석(Principal Component Analysis, PCA)\n",
        "#### 다중 변수들 간의 관계를 이해하고 차원 축소를 위해 사용되는 분석 방법 예를 들어, 다양한 인종 퍼센트와 소득 수준과의 관계를 파악하기 위해 PCA를 사용하여 데이터의 차원을 축소하고 주성분을 도출할 수 있습니다."
      ],
      "metadata": {
        "id": "lKZKnFsADJmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 다중 선형 회귀 (Multiple Linear Regression)\n",
        "#### 소득수준과 인종을 동시에 사용하여 혐오범죄수에 미치는 영향을 분석 \n",
        "#### 소득수준과 인종을 독립 변수로 혐오범죄수를 종속 변수로 설정하여 수행."
      ],
      "metadata": {
        "id": "k4ahAqoNEmw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 결정 계수 (R-squared)는 회귀 분석에서 종속 변수의 변동성을 독립 변수로 설명하는 정도를 나타내는 지표\n",
        "  - R-squared 값은 0에서 1 사이의 값을 가지며, 높을수록 독립 변수가 종속 변수의 변동성을 잘 설명한다는 것을 의미"
      ],
      "metadata": {
        "id": "uJKfqKq3Fss6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 우선, 독립변수들 간의 다중공선성(Multicollinearity) 판단\n",
        "#### 회귀분석의 전제 가정 : 독립변수들 간에 상관관계가 높으면 안됨\n",
        "#### 일반적으로 5 이상의 값이 나타나면 다중공선성의 증거로 간주"
      ],
      "metadata": {
        "id": "zBIwpafUHYos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "datasets = [data_2017, data_2018, data_2019, data_2020, data_2021]\n",
        "\n",
        "# Perform regression analysis for each dataset\n",
        "for i, data in enumerate(datasets):\n",
        "    print(f\"Dataset: data_{2017 + i}\")\n",
        "\n",
        "    # 독립 변수만 선택\n",
        "    X = data[['median_income', 'Black', 'Hispanic', 'Asian', 'Multiple']]\n",
        "\n",
        "    # VIF 계산\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"Features\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    # 결과 출력\n",
        "    print(vif)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOK6XRqvHqpO",
        "outputId": "1247a448-58f8-4267-b50c-be0a037a0d93"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: data_2017\n",
            "        Features       VIF\n",
            "0  median_income  1.985090\n",
            "1          Black  2.172472\n",
            "2       Hispanic  2.487377\n",
            "3          Asian  2.298526\n",
            "4       Multiple  1.804589\n",
            "Dataset: data_2018\n",
            "        Features        VIF\n",
            "0  median_income   1.380055\n",
            "1          Black   5.940042\n",
            "2       Hispanic   6.329694\n",
            "3          Asian   4.485327\n",
            "4       Multiple  10.271187\n",
            "Dataset: data_2019\n",
            "        Features       VIF\n",
            "0  median_income  2.051197\n",
            "1          Black  2.022737\n",
            "2       Hispanic  1.438537\n",
            "3          Asian  1.446182\n",
            "4       Multiple  1.856140\n",
            "Dataset: data_2020\n",
            "        Features       VIF\n",
            "0  median_income  2.371702\n",
            "1          Black  1.635947\n",
            "2       Hispanic  1.572015\n",
            "3          Asian  2.672712\n",
            "4       Multiple  1.667103\n",
            "Dataset: data_2021\n",
            "        Features       VIF\n",
            "0  median_income  2.681765\n",
            "1          Black  2.386352\n",
            "2       Hispanic  3.251136\n",
            "3          Asian  4.263103\n",
            "4       Multiple  2.304328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data_2018을 제외하고서는 VIF값이 다 작으므로 회귀분석 가능\n",
        "- data_2018은 다중공선성을 해결할 필요가 있음 : e.g., 변수선택, 변수변환, PCA, 규제모델\n",
        "  - 변수선택 : 다중공선성이 강하게 나타나는 변수들을 제거하여 모델에 포함시키기\n",
        "  - 변수변환 : 변수들을 다른 형태로 변환하여 다중공선성 줄이기(e.g., 표준화, 로그변환 등)\n",
        "  - PCA : 변수들 간의 선형 종속성을 고려하여 변수들을 새로운 주성분으로 변환\n",
        "  - 규제모델 : 릿지 or 라쏘 등을 활용하여 계수의 크기를 조절\n",
        "- 변수변환 선택"
      ],
      "metadata": {
        "id": "JIxbX5N2KIUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = data_2018\n",
        "\n",
        "# 변수 변환을 위해 변수들을 선택\n",
        "selected_features = ['median_income', 'Black', 'Hispanic', 'Asian', 'Multiple']\n",
        "\n",
        "# 변수들의 데이터를 표준화\n",
        "scaler = StandardScaler()\n",
        "data[selected_features] = scaler.fit_transform(data[selected_features])\n",
        "\n",
        "data_2018 = data"
      ],
      "metadata": {
        "id": "rbiGnHbQLy6E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_2018에 대해 다중공선성 판단 재실시\n",
        "# 독립 변수만 선택\n",
        "X = data[['median_income', 'Black', 'Hispanic', 'Asian', 'Multiple']]\n",
        "\n",
        "# VIF 계산\n",
        "vif = pd.DataFrame()\n",
        "vif[\"Features\"] = X.columns\n",
        "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "# 결과 출력\n",
        "print(vif)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoPdXaWNMFdD",
        "outputId": "bf9170ce-9bcc-4813-c1f2-8c37585e9530"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Features       VIF\n",
            "0  median_income  1.262111\n",
            "1          Black  5.606133\n",
            "2       Hispanic  5.690731\n",
            "3          Asian  4.019919\n",
            "4       Multiple  8.922317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다중회귀분석 진\n",
        "datasets = [data_2017, data_2018, data_2019, data_2020, data_2021]\n",
        "\n",
        "# Perform regression analysis for each dataset\n",
        "for i, data in enumerate(datasets):\n",
        "    print(f\"Dataset: data_{2017 + i}\")\n",
        "    \n",
        "    # 독립 변수와 종속 변수 설정\n",
        "    X = data[['median_income', 'Black', 'Hispanic', 'Asian', 'Multiple']]\n",
        "    y = data['hate_crime_case_normalized']\n",
        "\n",
        "    # 상수 (절편) 추가\n",
        "    X = sm.add_constant(X)\n",
        "    \n",
        "    # 다중 선형 회귀 모델 학습\n",
        "    model = sm.OLS(y, X).fit()\n",
        "\n",
        "    # 회귀 분석 결과 출력\n",
        "    print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxkaWjD-E8Hm",
        "outputId": "f3789498-e65b-49d4-cecb-ed1914fe34dc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: data_2017\n",
            "                                OLS Regression Results                                \n",
            "======================================================================================\n",
            "Dep. Variable:     hate_crime_case_normalized   R-squared:                       0.728\n",
            "Model:                                    OLS   Adj. R-squared:                  0.698\n",
            "Method:                         Least Squares   F-statistic:                     24.10\n",
            "Date:                        Mon, 29 May 2023   Prob (F-statistic):           1.04e-11\n",
            "Time:                                16:48:18   Log-Likelihood:                -226.90\n",
            "No. Observations:                          51   AIC:                             465.8\n",
            "Df Residuals:                              45   BIC:                             477.4\n",
            "Df Model:                                   5                                         \n",
            "Covariance Type:                    nonrobust                                         \n",
            "=================================================================================\n",
            "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------\n",
            "const           -71.9955     18.967     -3.796      0.000    -110.197     -33.794\n",
            "median_income     0.0013      0.000      4.335      0.000       0.001       0.002\n",
            "Black            -1.4082      1.492     -0.944      0.350      -4.412       1.596\n",
            "Hispanic         98.6157     14.878      6.628      0.000      68.649     128.582\n",
            "Asian            11.4913     27.471      0.418      0.678     -43.839      66.821\n",
            "Multiple          3.7832      6.311      0.599      0.552      -8.927      16.494\n",
            "==============================================================================\n",
            "Omnibus:                       18.202   Durbin-Watson:                   2.028\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               68.497\n",
            "Skew:                          -0.629   Prob(JB):                     1.34e-15\n",
            "Kurtosis:                       8.536   Cond. No.                     6.03e+05\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 6.03e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "Dataset: data_2018\n",
            "                                OLS Regression Results                                \n",
            "======================================================================================\n",
            "Dep. Variable:     hate_crime_case_normalized   R-squared:                       0.393\n",
            "Model:                                    OLS   Adj. R-squared:                  0.323\n",
            "Method:                         Least Squares   F-statistic:                     5.574\n",
            "Date:                        Mon, 29 May 2023   Prob (F-statistic):           0.000481\n",
            "Time:                                16:48:18   Log-Likelihood:                -241.55\n",
            "No. Observations:                          49   AIC:                             495.1\n",
            "Df Residuals:                              43   BIC:                             506.5\n",
            "Df Model:                                   5                                         \n",
            "Covariance Type:                    nonrobust                                         \n",
            "=================================================================================\n",
            "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------\n",
            "const            27.2601      5.104      5.341      0.000      16.967      37.554\n",
            "median_income    17.9366      5.734      3.128      0.003       6.373      29.501\n",
            "Black            10.6591     12.085      0.882      0.383     -13.713      35.031\n",
            "Hispanic         31.0039     12.176      2.546      0.015       6.448      55.559\n",
            "Asian           -15.8134     10.234     -1.545      0.130     -36.452       4.825\n",
            "Multiple        -21.7002     15.246     -1.423      0.162     -52.447       9.047\n",
            "==============================================================================\n",
            "Omnibus:                       33.290   Durbin-Watson:                   2.163\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              130.034\n",
            "Skew:                           1.599   Prob(JB):                     5.80e-29\n",
            "Kurtosis:                      10.312   Cond. No.                         7.18\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "Dataset: data_2019\n",
            "                                OLS Regression Results                                \n",
            "======================================================================================\n",
            "Dep. Variable:     hate_crime_case_normalized   R-squared:                       0.892\n",
            "Model:                                    OLS   Adj. R-squared:                  0.880\n",
            "Method:                         Least Squares   F-statistic:                     74.34\n",
            "Date:                        Mon, 29 May 2023   Prob (F-statistic):           1.32e-20\n",
            "Time:                                16:48:18   Log-Likelihood:                -209.18\n",
            "No. Observations:                          51   AIC:                             430.4\n",
            "Df Residuals:                              45   BIC:                             442.0\n",
            "Df Model:                                   5                                         \n",
            "Covariance Type:                    nonrobust                                         \n",
            "=================================================================================\n",
            "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------\n",
            "const           -51.4616     14.276     -3.605      0.001     -80.214     -22.709\n",
            "median_income     0.0009      0.000      4.016      0.000       0.000       0.001\n",
            "Black            -2.3807      0.957     -2.487      0.017      -4.309      -0.453\n",
            "Hispanic         82.8846      6.441     12.869      0.000      69.912      95.857\n",
            "Asian            17.7461      7.564      2.346      0.023       2.511      32.982\n",
            "Multiple         22.3048      6.433      3.467      0.001       9.347      35.262\n",
            "==============================================================================\n",
            "Omnibus:                        0.078   Durbin-Watson:                   2.051\n",
            "Prob(Omnibus):                  0.962   Jarque-Bera (JB):                0.217\n",
            "Skew:                          -0.081   Prob(JB):                        0.897\n",
            "Kurtosis:                       2.725   Cond. No.                     4.67e+05\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 4.67e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "Dataset: data_2020\n",
            "                                OLS Regression Results                                \n",
            "======================================================================================\n",
            "Dep. Variable:     hate_crime_case_normalized   R-squared:                       0.805\n",
            "Model:                                    OLS   Adj. R-squared:                  0.784\n",
            "Method:                         Least Squares   F-statistic:                     37.26\n",
            "Date:                        Mon, 29 May 2023   Prob (F-statistic):           6.45e-15\n",
            "Time:                                16:48:18   Log-Likelihood:                -207.67\n",
            "No. Observations:                          51   AIC:                             427.3\n",
            "Df Residuals:                              45   BIC:                             438.9\n",
            "Df Model:                                   5                                         \n",
            "Covariance Type:                    nonrobust                                         \n",
            "=================================================================================\n",
            "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------\n",
            "const           -41.0779     12.868     -3.192      0.003     -66.996     -15.160\n",
            "median_income     0.0007      0.000      3.621      0.001       0.000       0.001\n",
            "Black             1.0760      0.301      3.577      0.001       0.470       1.682\n",
            "Hispanic         38.6050      7.557      5.108      0.000      23.384      53.826\n",
            "Asian            34.1658     11.216      3.046      0.004      11.576      56.755\n",
            "Multiple         19.7599      4.034      4.898      0.000      11.634      27.886\n",
            "==============================================================================\n",
            "Omnibus:                        8.912   Durbin-Watson:                   1.904\n",
            "Prob(Omnibus):                  0.012   Jarque-Bera (JB):               13.466\n",
            "Skew:                          -0.461   Prob(JB):                      0.00119\n",
            "Kurtosis:                       5.342   Cond. No.                     4.45e+05\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 4.45e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "Dataset: data_2021\n",
            "                                OLS Regression Results                                \n",
            "======================================================================================\n",
            "Dep. Variable:     hate_crime_case_normalized   R-squared:                       0.558\n",
            "Model:                                    OLS   Adj. R-squared:                  0.509\n",
            "Method:                         Least Squares   F-statistic:                     11.38\n",
            "Date:                        Mon, 29 May 2023   Prob (F-statistic):           3.93e-07\n",
            "Time:                                16:48:18   Log-Likelihood:                -202.48\n",
            "No. Observations:                          51   AIC:                             417.0\n",
            "Df Residuals:                              45   BIC:                             428.5\n",
            "Df Model:                                   5                                         \n",
            "Covariance Type:                    nonrobust                                         \n",
            "=================================================================================\n",
            "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------\n",
            "const           -18.3034     11.737     -1.559      0.126     -41.943       5.336\n",
            "median_income     0.0004      0.000      2.837      0.007       0.000       0.001\n",
            "Black             0.4397      0.442      0.995      0.325      -0.450       1.330\n",
            "Hispanic         45.4155     15.613      2.909      0.006      13.970      76.861\n",
            "Asian            13.9992      8.412      1.664      0.103      -2.943      30.941\n",
            "Multiple          9.2489      5.839      1.584      0.120      -2.511      21.009\n",
            "==============================================================================\n",
            "Omnibus:                        6.539   Durbin-Watson:                   2.029\n",
            "Prob(Omnibus):                  0.038   Jarque-Bera (JB):                5.951\n",
            "Skew:                           0.831   Prob(JB):                       0.0510\n",
            "Kurtosis:                       3.196   Cond. No.                     6.68e+05\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 6.68e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "R-squared\n",
        "- data_2017 : 0.728\n",
        "- data_2018 : 0.393\n",
        "- data_2019 : 0.892 => 매우 큰 편\n",
        "- data_2020 : 0.805 => 매우 큰 편\n",
        "- data_2021 : 0.558\n",
        "\n",
        "\n",
        "F-statistic\n",
        "- data_2017 : 24.10\n",
        "- data_2018 : 5.574\n",
        "- data_2019 : 74.34\n",
        "- data_2020 : 37.26\n",
        "- data_2021 : 11.38\n",
        "\n",
        "Cond.No.(=다중공선성을 의미) 값이 대체로 다 크게 나타남 + Strong Multicollineartiy가 존재할 수 있다고 경고 제시 -> 안 하는 게 나을 듯..."
      ],
      "metadata": {
        "id": "EmMLZ0zBa5lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "income_threshold = 50000\n",
        "\n",
        "high_income = data_2017[data_2017['median_income'] >= income_threshold]['hate_crime_case_normalized']\n",
        "low_income = data_2017[data_2017['median_income'] < income_threshold]['hate_crime_case_normalized']\n",
        "result = stats.ttest_ind(high_income, low_income)\n",
        "print(f\"p-value: {result.pvalue}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIybXs7WkeGt",
        "outputId": "8e8374c7-d5b2-413e-f443-2b6d84ab4a95"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p-value: 0.618041703286677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# t-test\n",
        "# 높은 소득수준 지역과 낮은 소득수준 그룹 간의 범죄횟수 평균 차이 검정\n",
        "import scipy.stats as stats\n",
        "\n",
        "def perform_t_test(data, income_threshold):\n",
        "    high_income = data[data['median_income'] >= income_threshold]['hate_crime_case_normalized']\n",
        "    low_income = data[data['median_income'] < income_threshold]['hate_crime_case_normalized']\n",
        "    result = stats.ttest_ind(high_income, low_income)\n",
        "    return result\n",
        "\n",
        "income_threshold = 150000  # 소득수준을 기준으로 높은 소득수준과 낮은 소득수준을 구분하기 위한 임계값 설정\n",
        "\n",
        "datasets = [data_2018, data_2019, data_2020, data_2021]\n",
        "\n",
        "for year, dataset in enumerate(datasets):\n",
        "    print(f\"Dataset: data_{2018 + year}\")\n",
        "    result = perform_t_test(dataset, income_threshold)\n",
        "    print(f\"p-value: {result.pvalue}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk88rR8qisMQ",
        "outputId": "5a2a27f3-4fbd-4b8d-f652-6d2128783d2f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: data_2018\n",
            "p-value: nan\n",
            "Dataset: data_2019\n",
            "p-value: nan\n",
            "Dataset: data_2020\n",
            "p-value: nan\n",
            "Dataset: data_2021\n",
            "p-value: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nan 출력 이유 : 해당 그룹의 데이터 부족 , 분산이 없어서 t-test수행 불가능 \n",
        "\n",
        "=> 소득 수준을 나누는 기준을 낮춰봤음에도 불구하고 안 나옴\n",
        "\n",
        "전처리 과정을 다시 할 필요가 있음...-> 근데, how?"
      ],
      "metadata": {
        "id": "g_UgdV8IlJL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 기각/채택 판단"
      ],
      "metadata": {
        "id": "hBbVhFbY_ENg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 회귀 분석에 대한 결과\n",
        "\n",
        "Dataset: data_2017\n",
        "P-value: 0.00017068995397843416\n",
        "\n",
        "Dataset: data_2018\n",
        "P-value: 4.940820673264162e-05\n",
        "\n",
        "Dataset: data_2019\n",
        "P-value: 1.3917103990576532e-06\n",
        "\n",
        "Dataset: data_2020\n",
        "P-value: 0.00017064324446323457\n",
        "\n",
        "Dataset: data_2021\n",
        "P-value: 0.0184617865690403\n",
        "\n",
        "\n",
        "\n",
        "- 피어슨 상관계수에 대한 결과 \n",
        "\n",
        "Year: 2017, Pearson Correlation Coefficient: 0.5026505362463362\n",
        "\n",
        "Year: 2018, Pearson Correlation Coefficient: 0.5460568674434366\n",
        "\n",
        "Year: 2019, Pearson Correlation Coefficient: 0.6174406329516006\n",
        "\n",
        "Year: 2020, Pearson Correlation Coefficient: 0.5026584234922596\n",
        "\n",
        "Year: 2021, Pearson Correlation Coefficient: 0.3288552548021082"
      ],
      "metadata": {
        "id": "vE-Jfb03g0g_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TOaACmsah8dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 회귀 분석 결과\n",
        "\n",
        "모든 데이터셋에서 p-value가 유의수준인 0.05보다 많이 작게 나옴.\n",
        "이는 소득수준과 범죄 횟수 간에 통계적으로 유의한 관계가 있음을 나타냄.\n",
        "따라서, 회귀 분석 결과는 귀무가설을 기각하고 대립가설을 채택가능.\n",
        "\n",
        "- 피어슨 상관계수 결과\n",
        "\n",
        "모든 데이터셋에서 피어슨 상관계수가 양수로 나타남\n",
        "상관계수 값이 0에 가까울수록 관련성이 약하고, 1에 가까울수록 관련성이 강함.\n",
        "모든 연도에서 상관계수가 양수이며, 일부 연도에서는 0.5 이상의 상관계수를 보였음.\n",
        "이는 소득수준과 범죄 횟수 간에 양적인 관련이 있음을 시사함.\n",
        "따라서, 피어슨 상관계수 결과도 가설을 지지\n",
        "\n",
        "## 결과\n",
        "결과적으로, 회귀 분석과 피어슨 상관계수 결과 모두 소득수준과 범죄 횟수 간의 관련성을 지지하므로 가설로 내세운 \"소득수준이 높을수록 범죄 횟수가 적을 것이다\"는 채택될 수 있음."
      ],
      "metadata": {
        "id": "-gis3wK8hIAZ"
      }
    }
  ]
}